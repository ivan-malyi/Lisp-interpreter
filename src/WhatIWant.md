
1. Определим какие ошибки должны определяться на лексическом анализе, а какие на синтаксическом. Лексическим анализом занимается мой коллега, я ему передам информацию о том на какие ошибки он должен реагирвать, предварительно перед тем как передать мне вектор стрктуры Token. Структура Token выглядит следующим образом:

```rust 
#[allow(dead_code)]
*// Определение типов токенов*
pub *enum* TokenType {
 LeftParen, *// (*
 RightParen, *// )*
 Symbol, *// идентификаторы*
 Number, *// числа*
 String, *// строки*
 Boolean, *// типа bool*
*// другие типы...*
}
#[allow(dead_code)]
*// Структура токена*
pub *struct* Token {
pub token_type: TokenType,
pub lexeme: String, *// исходный текст*
pub line: usize, *// номер строки*
pub column: usize, *// номер колонки*
}
```

2. Принимая вектор из стурктур "Token" , что, по сути, равносильно приему одной строки кода - мы ее провреяем на ошибки если все хорошо - добавляем в условную секцию "Ready Code", путем создания из проверенного вектора структуру с названием ReadyVec, вот ее определение: 
```rust
pub *struct* ReadyVec {
 vect_tokens: Vec<Token>,
vect_line: usize,
*// Хранит отображение от некоторого ключа к индексу в tokens*
indices: HashMap<String, usize>,
}
```
Как мы видим, структура ReadyVec хранит хэш - этот хэш генерируется сразу после того как функция проверки на синтаксические ошибки вернет true, ориентеровочно она будет называться и віглядеть так: 
```rust
fn is_vect_ready(check_vect: Vect<Token>){

} 
```

3.  Несмотря на то успешно ли нам удалось интерпритировать все вектора, или только их часть - у нас выходит секция `"Ready Code"` с каким то количеством (от 0 до n, где n - количество векторов (строк кода))  векторов, содержашихся в ней. В случае возникновения ошибки на каком то обрабатываемом векторе - мы не в коем случае не очищаем секцию `"Ready Code"`, а всего лишь останавливаем наше выполнения на текущем векторе с текущим количеством векторов в условных секциях `New Code"` и `"Ready Code"`, где `"New Code"` - это по сути от текущего указатель(`ptr`) и до n - `(n - ptr)`, а `"Ready Code"` хранит в себе `(ptr - 1 )` количество векторов. Мы предполагаем, что пользователь устранит ошибку, без явного изменения кода, который идет до (мы не рассматриваем сложные ситуации, когда ошибка, вызвана в строке `k` - зависит от строки `k - i` и прочих), но наша функция, которая возобновляет процесс - должна ссылаться на функцию компоратор, которая по сути сообщает нам, сможем ли мы интерпритировать код с `ptr` и до `n`, или нам нужно  обнулить ptr и начать собирать древо заново. На данном этапе компоратор будет работать довольно примитивно - пробегать `"New Code"` с самого начала и сравнивать хэши векторов  на i позиции с уже доступными ему хэшами `i` векторов в секции `"Ready Code"` - если хэши несовпадают - возращать `кф` равным 0, если все совпали - возраащать `кф` равным 1. В дальнейшей реализации мы добавим более четкие и логичные правила работы компоратора, где каждое правило в той или иной степени будет влиять на выходной `кф`. Кф будет в диапазоне от 0 до 1, где нам будте достаточно 0.5 и выше , чтобы не выполнять операцию пересборки древа, а всего лишь выполнить некоторые операции с уже существующей областью "Ready Code", тем самым оптимальными действиями увеличивая кф.
4. Древо, состоящее из n векторов  - конечный результат , к которому стремится наш интерпритатор, по достежению которого мы выводим краткое, сответсвующее сообщение в консоль.